---

# ğŸ§  MRI-to-Synthetic CT Brain Scan Translation using Deep Learning

ğŸš€ **A Capstone Project by Meet Jani**
ğŸ“ *Indian Institute of Technology (IIT) Mandi, in collaboration with Masai School*

---

## ğŸ“– Project Overview

* This project focuses on generating **synthetic CT brain scans from MRI inputs** using **deep learning**.

* MRI offers excellent soft-tissue contrast, whereas CT provides superior visualization of bones and tissue density.

* Obtaining both scans for every patient is costly and exposes patients to radiation.

* To address this, I built multiple **deep learning architectures** â€” from classical **U-Net** to advanced **Pix2Pix GAN** and **Swin Transformer-based** models â€” to perform **MRI â†’ CT translation** with high structural and perceptual accuracy.

---

## ğŸ¯ Objectives

âœ… Build deep learning models that generate CT-like brain images from MRI scans.

âœ… Compare architectures across **MAE, MSE, PSNR, SSIM** metrics.

âœ… Design efficient preprocessing and RAM-caching pipelines for faster training.

âœ… Deploy an interactive **Gradio web app** for real-time inference and visualization.

---

## ğŸ“‚ Dataset

**Dataset:** [SynthRAD2023 Brain Task-1](https://synthrad2023.grand-challenge.org)
**Samples:** 180 paired T1-weighted MRI and CT volumes

### ğŸ§© Preprocessing Pipeline

* 3D MRI/CT volume alignment â†’ 2D paired slice generation
* Intensity normalization per slice
* Optional brain masking for region-specific learning
* Data augmentation (flips, rotations, brightness/contrast, Gaussian noise)
* **In-memory caching** for high-speed data loading during training

---

## ğŸ§  Model Architectures

| Model               | Generator               | Discriminator | Loss Functions          | Notes                       |
| ------------------- | ----------------------- | ------------- | ----------------------- | --------------------------- |
| **UNet**            | UNet                    | None          | L1                      | Baseline                    |
| **Pix2Pix**         | UNet                    | PatchGAN      | L1 + Adversarial        | Best overall balance        |
| **Pix2Pix-ResUNet** | ResUNet                 | PatchGAN      | L1 + SSIM + Adversarial | Sharper details             |
| **SwinPix2Pix**     | UNet + Swin Transformer | PatchGAN      | L1 + Adversarial        | Captures long-range context |
| **SwinGAN**         | SwinUNet                | PatchGAN      | L1 + SSIM + Adversarial | Transformer-based synthesis |

**Optimizer:** Adam (lr = 0.0002, Î²â‚ = 0.5, Î²â‚‚ = 0.999)
**Batch Size:** 4â€“12 slices (GPU-dependent)â€ƒâ€¢â€ƒ**Precision:** Mixed (AMP)

---

## âš™ï¸ Training & Evaluation

**Losses**

* L1 Loss â†’ pixel-level accuracy
* Adversarial Loss (BCE) â†’ GAN realism
* SSIM Loss â†’ perceptual similarity

**Metrics**

* **MAE**, **MSE** â†’ intensity accuracy
* **PSNR** â†’ image fidelity
* **SSIM** â†’ structural similarity

**Validation Results (Best Models)**

| Model           | PSNR      | SSIM      | MAE       | MSE       |
| --------------- | --------- | --------- | --------- | --------- |
| UNet            | 19.74     | 0.755     | 0.232     | 0.197     |
| **Pix2Pix**     | **23.63** | **0.856** | **0.125** | **0.095** |
| Pix2Pix-ResUNet | 23.89     | 0.851     | 0.117     | 0.088     |
| SwinPix2Pix     | 21.40     | 0.780     | 0.160     | 0.143     |

**Inference Speed**

* GPU â‰ˆ 0.3 s/sliceâ€ƒâ€¢â€ƒCPU â‰ˆ 3 s/slice

---

## ğŸŒ Web App Deployment

**Framework:** Gradio

**Features**

* Upload MRI slice (and optional mask)
* Generate synthetic CT in real-time
* Display MAE, MSE, PSNR, SSIM metrics
* Download results as `.png` or `.nii`

---

## ğŸ“Š Results

| Model          | PSNR | SSIM  | Qualitative Observations        |
| -------------- | ---- | ----- | ------------------------------- |
| **Pix2Pix**    | 23.6 | 0.86  | Balanced sharpness & smoothness |
| **ResUNet**    | 23.9 | 0.85  | Sharper edges, slightly slower  |
| **Swin-based** | ~21  | ~0.78 | Noisier due to limited data     |

### ğŸ–¼ Visual Comparison

| Input MRI               | Ground Truth CT       | Predicted CT              | Error Map                   |
| ----------------------- | --------------------- | ------------------------- | --------------------------- |
| ![MRI](results/mri.png) | ![CT](results/ct.png) | ![Pred](results/pred.png) | ![Error](results/error.png) |

> ğŸ“ Place these sample images in a `results/` folder within your repo.

---

## ğŸ§© Innovations & Contributions

âœ… **RAM Caching** â€“ accelerated training via in-memory dataset
âœ… **Slice-wise Augmentation** â€“ improves robustness to variation
âœ… **Comprehensive Metric Pipeline** â€“ MAE, MSE, PSNR, SSIM per-slice & per-patient
âœ… **Lightweight Web App** â€“ deployable MRIâ†’CT translator demo

---

## ğŸš€ Getting Started

```bash
# 1. Install dependencies
pip install -r requirements.txt

# 2. Open the notebook
jupyter notebook capstone-project.ipynb

# 3. Train model (U-Net / Pix2Pix)
#   Run training cells inside the notebook

# 4. Evaluate results
#   Use evaluation cells to compute metrics

# 5. Launch Gradio web demo
#   Run final cell with iface.launch()
```

---

## ğŸ§® Requirements

* Python â‰¥ 3.8
* PyTorch with CUDA support
* NumPy â€¢ SciPy â€¢ scikit-image â€¢ scikit-learn
* NiBabel â€¢ tqdm â€¢ Gradio â€¢ pytorch-msssim

---

## ğŸ§­ Future Work

* Extend to 3D volumetric U-Net models
* Integrate multi-modal MRI inputs
* Explore CNN + Transformer hybrids
* Validate clinically via PACS integration

---

## ğŸ‘¨â€ğŸ’» Author

**Meet Jani**
ğŸ“§ [janimeet59@gmail.com](mailto:janimeet59@gmail.com)

ğŸ”— [**LinkedIn**](https://linkedin.com/in/meetjani0)â€ƒ|â€ƒ[**GitHub**](https://github.com/MeetJani0)

ğŸ“ *Minor in Data Science & Machine Learning â€” IIT Mandi (in collaboration with Masai School)*

---

â­ If you found this work interesting, feel free to connect or star the repository!

---
